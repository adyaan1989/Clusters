{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a12e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a943b89",
   "metadata": {},
   "source": [
    "https://thinkingneuron.com/how-to-use-artificial-neural-networks-for-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21203530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the train (26570, 26)\n",
      "shape of the test (20775, 25)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv/train.csv')\n",
    "test = pd.read_csv('test.csv/test.csv')\n",
    "\n",
    "print(\"shape of the train\", train.shape)\n",
    "print(\"shape of the test\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ead6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the product_Code as this feature is have equal categories in train and test\n",
    "train.drop(\"product_code\",\"id\", axis=1, inplace=True)\n",
    "test.drop(\"product_code\",\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667a1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns[train.isnull().any(axis=0)]:\n",
    "    train[i].fillna(train[i].mean(), inplace=True)\n",
    "\n",
    "for i in test.columns[test.isnull().any(axis=0)]:\n",
    "    test[i].fillna(test[i].mean(), inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c56cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the attribute_2 and attribute_3\n",
    "train[\"attribute_0\"] = pd.factorize(train.attribute_0)[0]\n",
    "train[\"attribute_1\"] = pd.factorize(train.attribute_1)[0]\n",
    "\n",
    "test[\"attribute_0\"] = pd.factorize(test.attribute_0)[0]\n",
    "test[\"attribute_1\"] = pd.factorize(test.attribute_1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cc73765",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"failure\"], axis=1)\n",
    "y = train[\"failure\"]\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X, oversampled_Y = sm.fit_resample(X, y)\n",
    "oversampled = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99d79d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29289, 24), (29289,), (12553, 24), (12553,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "X_smot = oversampled.drop(\"failure\", axis=1)\n",
    "y_smot = oversampled.failure\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smot, y_smot, test_size=0.3, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4f4b846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25239</th>\n",
       "      <td>25239</td>\n",
       "      <td>299.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>15.931000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.432000</td>\n",
       "      <td>13.864000</td>\n",
       "      <td>16.343000</td>\n",
       "      <td>16.458000</td>\n",
       "      <td>8.366000</td>\n",
       "      <td>16.114000</td>\n",
       "      <td>15.452000</td>\n",
       "      <td>14.960000</td>\n",
       "      <td>13.287000</td>\n",
       "      <td>635.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>101.070000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17.295000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.060000</td>\n",
       "      <td>12.471000</td>\n",
       "      <td>16.346000</td>\n",
       "      <td>18.377000</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>15.562000</td>\n",
       "      <td>16.154000</td>\n",
       "      <td>17.172000</td>\n",
       "      <td>826.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7590</th>\n",
       "      <td>7590</td>\n",
       "      <td>208.230000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18.867000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.607000</td>\n",
       "      <td>9.429000</td>\n",
       "      <td>17.740000</td>\n",
       "      <td>16.873000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.553000</td>\n",
       "      <td>17.045000</td>\n",
       "      <td>14.712000</td>\n",
       "      <td>15.633000</td>\n",
       "      <td>841.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>4012</td>\n",
       "      <td>195.920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16.237000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.808000</td>\n",
       "      <td>11.518000</td>\n",
       "      <td>18.094000</td>\n",
       "      <td>19.762000</td>\n",
       "      <td>11.594000</td>\n",
       "      <td>15.175000</td>\n",
       "      <td>19.031000</td>\n",
       "      <td>11.782000</td>\n",
       "      <td>15.614000</td>\n",
       "      <td>848.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37375</th>\n",
       "      <td>8810</td>\n",
       "      <td>136.217714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>18.029496</td>\n",
       "      <td>...</td>\n",
       "      <td>17.436073</td>\n",
       "      <td>12.125232</td>\n",
       "      <td>17.478043</td>\n",
       "      <td>17.436570</td>\n",
       "      <td>12.166866</td>\n",
       "      <td>17.389038</td>\n",
       "      <td>16.105981</td>\n",
       "      <td>15.397505</td>\n",
       "      <td>16.709641</td>\n",
       "      <td>543.924489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>20757</td>\n",
       "      <td>67.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>17.586000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.372000</td>\n",
       "      <td>9.839000</td>\n",
       "      <td>17.141000</td>\n",
       "      <td>18.740000</td>\n",
       "      <td>13.570000</td>\n",
       "      <td>14.840000</td>\n",
       "      <td>17.702000</td>\n",
       "      <td>13.499000</td>\n",
       "      <td>17.379000</td>\n",
       "      <td>725.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>6224</td>\n",
       "      <td>101.988667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>18.192487</td>\n",
       "      <td>...</td>\n",
       "      <td>19.161521</td>\n",
       "      <td>12.282076</td>\n",
       "      <td>16.359902</td>\n",
       "      <td>18.047104</td>\n",
       "      <td>11.266990</td>\n",
       "      <td>16.166531</td>\n",
       "      <td>15.617748</td>\n",
       "      <td>15.342995</td>\n",
       "      <td>17.375088</td>\n",
       "      <td>773.866670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>14417</td>\n",
       "      <td>122.841726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>18.633366</td>\n",
       "      <td>...</td>\n",
       "      <td>20.289293</td>\n",
       "      <td>12.117769</td>\n",
       "      <td>15.971527</td>\n",
       "      <td>18.712220</td>\n",
       "      <td>11.455650</td>\n",
       "      <td>15.979220</td>\n",
       "      <td>14.254883</td>\n",
       "      <td>14.706385</td>\n",
       "      <td>16.752959</td>\n",
       "      <td>794.163772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>21243</td>\n",
       "      <td>125.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19.195000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.681000</td>\n",
       "      <td>10.818000</td>\n",
       "      <td>15.689000</td>\n",
       "      <td>17.289000</td>\n",
       "      <td>12.227000</td>\n",
       "      <td>15.652904</td>\n",
       "      <td>18.056000</td>\n",
       "      <td>18.273000</td>\n",
       "      <td>14.292000</td>\n",
       "      <td>614.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2732</td>\n",
       "      <td>66.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19.515000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.587000</td>\n",
       "      <td>10.693000</td>\n",
       "      <td>14.252000</td>\n",
       "      <td>19.043000</td>\n",
       "      <td>13.095000</td>\n",
       "      <td>17.066000</td>\n",
       "      <td>15.386000</td>\n",
       "      <td>14.229000</td>\n",
       "      <td>16.569000</td>\n",
       "      <td>525.514000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29289 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     loading  attribute_0  attribute_1  attribute_2  attribute_3  \\\n",
       "25239  25239  299.010000            0            2            6            9   \n",
       "3          3  101.070000            0            0            9            5   \n",
       "7590    7590  208.230000            1            1            8            8   \n",
       "4012    4012  195.920000            0            0            9            5   \n",
       "37375   8810  136.217714            1            1            8            8   \n",
       "...      ...         ...          ...          ...          ...          ...   \n",
       "20757  20757   67.010000            0            1            6            6   \n",
       "32103   6224  101.988667            1            1            8            8   \n",
       "30403  14417  122.841726            0            0            5            8   \n",
       "21243  21243  125.080000            0            2            6            9   \n",
       "2732    2732   66.010000            0            0            9            5   \n",
       "\n",
       "       measurement_0  measurement_1  measurement_2  measurement_3  ...  \\\n",
       "25239              5             12              3      15.931000  ...   \n",
       "3                 13              2              6      17.295000  ...   \n",
       "7590               2              3             12      18.867000  ...   \n",
       "4012              16              3              1      16.237000  ...   \n",
       "37375              3              9             11      18.029496  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "20757              4             11             10      17.586000  ...   \n",
       "32103              6              6              6      18.192487  ...   \n",
       "30403             11              8              7      18.633366  ...   \n",
       "21243              3              9              6      19.195000  ...   \n",
       "2732              11              2              0      19.515000  ...   \n",
       "\n",
       "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "25239      18.432000      13.864000       16.343000       16.458000   \n",
       "3          19.060000      12.471000       16.346000       18.377000   \n",
       "7590       19.607000       9.429000       17.740000       16.873000   \n",
       "4012       19.808000      11.518000       18.094000       19.762000   \n",
       "37375      17.436073      12.125232       17.478043       17.436570   \n",
       "...              ...            ...             ...             ...   \n",
       "20757      17.372000       9.839000       17.141000       18.740000   \n",
       "32103      19.161521      12.282076       16.359902       18.047104   \n",
       "30403      20.289293      12.117769       15.971527       18.712220   \n",
       "21243      17.681000      10.818000       15.689000       17.289000   \n",
       "2732       16.587000      10.693000       14.252000       19.043000   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "25239        8.366000       16.114000       15.452000       14.960000   \n",
       "3           10.020000       15.250000       15.562000       16.154000   \n",
       "7590        12.000000       17.553000       17.045000       14.712000   \n",
       "4012        11.594000       15.175000       19.031000       11.782000   \n",
       "37375       12.166866       17.389038       16.105981       15.397505   \n",
       "...               ...             ...             ...             ...   \n",
       "20757       13.570000       14.840000       17.702000       13.499000   \n",
       "32103       11.266990       16.166531       15.617748       15.342995   \n",
       "30403       11.455650       15.979220       14.254883       14.706385   \n",
       "21243       12.227000       15.652904       18.056000       18.273000   \n",
       "2732        13.095000       17.066000       15.386000       14.229000   \n",
       "\n",
       "       measurement_16  measurement_17  \n",
       "25239       13.287000      635.865000  \n",
       "3           17.172000      826.282000  \n",
       "7590        15.633000      841.357000  \n",
       "4012        15.614000      848.044000  \n",
       "37375       16.709641      543.924489  \n",
       "...               ...             ...  \n",
       "20757       17.379000      725.481000  \n",
       "32103       17.375088      773.866670  \n",
       "30403       16.752959      794.163772  \n",
       "21243       14.292000      614.373000  \n",
       "2732        16.569000      525.514000  \n",
       "\n",
       "[29289 rows x 24 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e32ed485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29289, 24)\n",
      "(29289,)\n",
      "(12553, 24)\n",
      "(12553,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_s = sc.fit_transform(X_train)\n",
    "X_test_s = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# X_train_s = pd.DataFrame(X_train_s, columns=cols)\n",
    "# X_test_s = pd.DataFrame(X_test_s, columns=cols)\n",
    "# X_train_s\n",
    "print(X_train_s.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test_s.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f287e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "# Defining the Input layer and FIRST hidden layer,both are same!\n",
    "# relu means Rectifier linear unit function\n",
    "classifier.add(Dense(units=8, kernel_initializer = \"uniform\", activation = \"relu\", input_dim=24))\n",
    "#Defining the SECOND hidden layer, here we have not defined input because it is\n",
    "# second layer and it will get input as the output of first hidden layer\n",
    "\n",
    "classifier.add(Dense(units=8, kernel_initializer=\"uniform\", activation = \"relu\"))\n",
    "#classifier.add(Dense(units=3, kernel_initializer=\"uniform\", activation = \"relu\"))\n",
    "\n",
    "# Defining the Output layer\n",
    "# sigmoid means sigmoid activation function\n",
    "# for Multiclass classification the activation ='softmax'\n",
    "# And output_dim will be equal to the number of factor levels\n",
    "classifier.add(Dense(units= 1,  kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "\n",
    "# Optimizer== the algorithm of SGG to keep updating weights\n",
    "# loss== the loss function to measure the accuracy\n",
    "# metrics== the way we will compare the accuracy after each step of SGD\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fitting the Neural Network on the training data\n",
    "classifier.fit(X_train_s , y_train, batch_size=10 , epochs=100, verbose=0)\n",
    "score, acc = classifier.evaluate(X_train_s, y_train, batch_size=10)\n",
    "print('Train score:', score)\n",
    "print('Train accuracy:', acc)\n",
    "score, acc = classifier.evaluate(X_test_s, y_test, batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "y_pred = classifier.predict(X_test_s)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Test accurancy\", accuracy_score(y_test, y_pred))\n",
    "print(\"Test number of correctly predicted\", accuracy_score(y_test, y_pred, normalize=False))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04dba678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256/1256 [==============================] - 2s 1ms/step - loss: 0.6632 - accuracy: 0.6058\n",
      "Test score: 0.6632312536239624\n",
      "Test accuracy: 0.605751633644104\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "400e1d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 0s 999us/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3adca2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6573b4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accurancy 0.6057516131602008\n",
      "Test number of correctly predicted 7604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3278, 2925],\n",
       "       [2024, 4326]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23567bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929/2929 [==============================] - 5s 1ms/step - loss: 0.6932 - accuracy: 0.5025\n",
      "Train score: 0.6931731104850769\n",
      "Train accuracy: 0.5025094747543335\n",
      "393/393 [==============================] - 1s 1ms/step\n",
      "********************\n",
      "1256/1256 [==============================] - 2s 2ms/step - loss: 0.6934 - accuracy: 0.4941\n",
      "Test score: 0.6933889985084534\n",
      "Test accuracy: 0.49414482712745667\n"
     ]
    }
   ],
   "source": [
    "# Improving the ANN\n",
    "from keras.layers import Dropout\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 24))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100,verbose = 0)\n",
    "\n",
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "score, acc = classifier.evaluate(X_train_s, y_train,\n",
    "                            batch_size=10)\n",
    "print('Train score:', score)\n",
    "print('Train accuracy:', acc)\n",
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_s)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print('*'*20)\n",
    "score, acc = classifier.evaluate(X_test_s, y_test,\n",
    "                            batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb2bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanusingh\\AppData\\Local\\Temp\\ipykernel_9908\\2513044805.py:13: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = build_classifier)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 697us/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 4ms/step\n",
      "92/92 [==============================] - 0s 4ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 2ms/step\n",
      "92/92 [==============================] - 0s 3ms/step\n",
      "92/92 [==============================] - 0s 3ms/step\n",
      "92/92 [==============================] - 0s 3ms/step\n",
      "92/92 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 24))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [100, 200],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train_s, y_train,verbose = 0)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print('Best Parameters after tuning: {}'.format(best_parameters))\n",
    "print('Best Accuracy after tuning: {}'.format(best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd37db",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using Manual Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d00c3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Parameters: batch_size: 6 - epochs: 5 Accuracy: 0.6347092986106873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanusingh\\AppData\\Local\\Temp\\ipykernel_9908\\3105877251.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  searchResults_data = searchResults.append(pd.DataFrame(data=[[trail_number,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Parameters: batch_size: 6 - epochs: 10 Accuracy: 0.6529072523117065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanusingh\\AppData\\Local\\Temp\\ipykernel_9908\\3105877251.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  searchResults_data = searchResults.append(pd.DataFrame(data=[[trail_number,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Parameters: batch_size: 6 - epochs: 50 Accuracy: 0.6535900831222534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanusingh\\AppData\\Local\\Temp\\ipykernel_9908\\3105877251.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  searchResults_data = searchResults.append(pd.DataFrame(data=[[trail_number,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(searchResults_data)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Calling the function\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbest_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36mbest_params\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m     18\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     19\u001b[0m classifier\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_trial\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Fetching the accuracy of the training\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#Accuracy = classifier.history['accuracy'][-1]\u001b[39;00m\n\u001b[0;32m     25\u001b[0m Accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining a function for finding best hyperparameters\n",
    "def best_params(X_train, y_train):\n",
    "    # Defining the list of hyper parameters to try\n",
    "    trail_number =0\n",
    "    batch_size_list = [6, 16,32, 64]\n",
    "    epochs_list =[5, 10, 50, 100]\n",
    "    \n",
    "    searchResults = pd.DataFrame(columns=[\"train_number\", \"Parameters\",\"Accuracy\"])\n",
    "    \n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epochs_list:\n",
    "            trail_number += 1\n",
    "        \n",
    "            # Creating the classifier ANN model\n",
    "            classifier = Sequential()\n",
    "            classifier.add(Dense(units=10, input_dim=24, kernel_initializer='uniform', activation=\"relu\"))\n",
    "            classifier.add(Dense(units=6, kernel_initializer='uniform', activation=\"relu\"))\n",
    "            classifier.add(Dense(units=1, kernel_initializer='uniform', activation= \"sigmoid\"))\n",
    "            classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "            \n",
    "            model = classifier.fit(X_train, y_train, batch_size=batch_size_trial , epochs=epochs_trial, verbose=0)\n",
    "            # Fetching the accuracy of the training\n",
    "            #Accuracy = classifier.history['accuracy'][-1]\n",
    "            Accuracy = model.history['accuracy'][-1]\n",
    "\n",
    "            # printing the results of the current iteration\n",
    "            print(trail_number, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', Accuracy)\n",
    "            searchResults_data = searchResults.append(pd.DataFrame(data=[[trail_number,\n",
    "                            'batch_size'+str(batch_size_trial)+'-'+'epoch'+str(epochs_trial), Accuracy]],\n",
    "                                                                    columns=['trainl_number', 'Parameters', 'Accuracy'] ))\n",
    "    return(searchResults_data)\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "results = best_params(X_train_s, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f4d48",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/shrutimechlearn/deep-tutorial-1-ann-and-classification/notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19768a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
